{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definition and Evaluation\n",
    "## Table of Contents\n",
    "1. [Model Selection](#model-selection)\n",
    "2. [Feature Engineering](#feature-engineering)\n",
    "3. [Hyperparameter Tuning](#hyperparameter-tuning)\n",
    "4. [Implementation](#implementation)\n",
    "5. [Evaluation Metrics](#evaluation-metrics)\n",
    "6. [Comparative Analysis](#comparative-analysis)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "\n",
    "We selected a three layered neural network with dropout layers in between and trained it for 30 epochs with a learning rate of 0.0005 with a validation split of 20%.\n",
    "We also adjusted the class weights since we had so few Seizure sequences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, InputLayer, Dropout, Conv1D, Conv2D, Flatten, Reshape, MaxPooling1D, MaxPooling2D, AveragePooling2D, BatchNormalization, Permute, ReLU, Softmax\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "\n",
    "EPOCHS = args.epochs or 30\n",
    "LEARNING_RATE = args.learning_rate or 0.0005\n",
    "# If True, non-deterministic functions (e.g. shuffling batches) are not used.\n",
    "# This is False by default.\n",
    "ENSURE_DETERMINISM = args.ensure_determinism\n",
    "# this controls the batch size, or you can manipulate the tf.data.Dataset objects yourself\n",
    "BATCH_SIZE = args.batch_size or 32\n",
    "if not ENSURE_DETERMINISM:\n",
    "    train_dataset = train_dataset.shuffle(buffer_size=BATCH_SIZE*4)\n",
    "train_dataset=train_dataset.batch(BATCH_SIZE, drop_remainder=False)\n",
    "validation_dataset = validation_dataset.batch(BATCH_SIZE, drop_remainder=False)\n",
    "\n",
    "# model architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(256, activation='relu',\n",
    "    activity_regularizer=tf.keras.regularizers.l1(0.00001)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(256, activation='relu',\n",
    "    activity_regularizer=tf.keras.regularizers.l1(0.00001)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(256, activation='relu',\n",
    "    activity_regularizer=tf.keras.regularizers.l1(0.00001)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(classes, name='y_pred', activation='softmax'))\n",
    "\n",
    "# this controls the learning rate\n",
    "opt = Adam(learning_rate=LEARNING_RATE, beta_1=0.9, beta_2=0.999)\n",
    "callbacks.append(BatchLoggerCallback(BATCH_SIZE, train_sample_count, epochs=EPOCHS, ensure_determinism=ENSURE_DETERMINISM))\n",
    "\n",
    "# train the neural network\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "model.fit(train_dataset, epochs=EPOCHS, validation_data=validation_dataset, verbose=2, callbacks=callbacks, class_weight=ei_tensorflow.training.get_class_weights(Y_train))\n",
    "\n",
    "# Use this flag to disable per-channel quantization for a model.\n",
    "# This can reduce RAM usage for convolutional models, but may have\n",
    "# an impact on accuracy.\n",
    "disable_per_channel_quantization = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "For our feature engineering we used prebuild blocks inside Edge Impulse consisting of: Syntiant IMU as well as Spectral analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "\n",
    "We trained the model multiple times with different dataset combinations and hyperparameter. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics\n",
    "\n",
    "We evaluated the Models based on their F1 scores, Accuracies and the precision of the seizure class because for our usecase that would be the most important Metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparative Analysis\n",
    "\n",
    "Our model outperformed the baseline model in terms of accuracy, F1 score of bost classed and the precision of the seizure class also improved, which shows that adding more non seizure data and optimizing the model improve the overall performance"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
